{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b0a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from copy import copy\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "# import project libraries\n",
    "project_path = Path('/home/ec2-user/SageMaker/david/tdm-sentiment/')\n",
    "sys.path.append(str(project_path / 'src'))\n",
    "#from get_sentiment.salience_index.salience_index import SalienceScorer\n",
    "#from get_data.tdm_parser.tdm_parser import TdmXmlParser\n",
    "# handle path\n",
    "data_path = project_path / 'data/'\n",
    "#corpus_name = 'ChicagoTribune'#'short_sample'  #TODO  # 'USATodayDavid' ChicagoTribune' 'Newyork20042023' TheWashingtonPostDavid, LosAngelesTimesDavid, StartupSentiment\n",
    "#folder_path = data_path / 'processed/results/' / corpus_name / 'chunk_11_data.csv'\n",
    "#corpus_path = Path(f'/home/ec2-user/SageMaker/data/{corpus_name}/')\n",
    "#df = pd.read_csv(folder_path)\n",
    "#df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15352ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder_path = data_path / 'processed/results/' / 'short_sample' / 'c_11_data.csv'\n",
    "#df1 = df[0:100]\n",
    "#df1.to_csv(save_folder_path, index=False)\n",
    "\n",
    "df2 = pd.read_csv(save_folder_path)\n",
    "df2 = df2[0:5]#['tf_idf_tags']\n",
    "df2.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_text(corpus_path, goid_number):\n",
    "    \"\"\"\n",
    "    Given a corpus path and a GOID, parse the corresponding XML\n",
    "    and return the article text.\n",
    "    \"\"\"\n",
    "    path = Path(corpus_path) / f\"{goid_number}.xml\"\n",
    "    soup = parser.get_xml_soup(path)\n",
    "    texts = parser.get_art_text(soup)\n",
    "    return texts\n",
    "\n",
    "def get_all_csv_files(folder_path):\n",
    "    # Use Path to find all CSV files in the folder\n",
    "    csv_files = list(Path(folder_path).glob('*.csv'))\n",
    "    return csv_files\n",
    "\n",
    "\n",
    "\n",
    "def concat_csv_files(folder_path):\n",
    "    # Get a list of all CSV files in the folder\n",
    "    csv_files = get_all_csv_files(folder_path)\n",
    "    \n",
    "    # Initialize an empty list to store DataFrames\n",
    "    df_list = []\n",
    "    \n",
    "    # Loop through the list of CSV files\n",
    "    for file in csv_files:\n",
    "        # Read each CSV file into a DataFrame\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        #goids = df['GOID'].to_list()\n",
    "        #results = Parallel(n_jobs=-1)(\n",
    "            #delayed(get_article_text)(corpus_path, goid) for goid in goids\n",
    "        #)\n",
    "        #df['Texts'] = results\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        df_list.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames in the list into a single DataFrame\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def md5_hash_text(text):\n",
    "    # If 'text' is a list, join its items into a single string.\n",
    "    if isinstance(text, list):\n",
    "        # Convert each item to string (in case they're not),\n",
    "        # then join them with a space (or any delimiter you want).\n",
    "        text = \" \".join(map(str, text))\n",
    "    \n",
    "    return hashlib.md5(text.encode('utf-8')).hexdigest()\n",
    "\n",
    "\n",
    "def get_text_string(text):\n",
    "    text = \" \".join(map(str, text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2f95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = concat_csv_files(folder_path)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719fcf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scorer and parser objects\n",
    "scorer = SalienceScorer()\n",
    "parser = TdmXmlParser()\n",
    "\n",
    "# Combine CSV files from all files\n",
    "combined_df = concat_csv_files(folder_path)\n",
    "\n",
    "# Combine 'International Herald Tribune' and 'New York Times' into one category\n",
    "combined_df['Publisher'] = combined_df['Publisher'].replace(\n",
    "    {'international herald tribune': 'new york times',\n",
    "     'new york times the': 'new york times',\n",
    "     'international new york times': 'new york times',\n",
    "     'los angeles times (pre-1997 fulltext)': 'los angeles times',\n",
    "     'washington post (pre-1997 fulltext) the': 'washington post the' }\n",
    ")\n",
    "combined_df = combined_df[combined_df['Publisher'] != 'new york times espa√±ol']\n",
    "combined_df = combined_df[combined_df[['bert_sentiment', 'Page']].notna().all(axis=1)]\n",
    "combined_df = combined_df.drop_duplicates(subset=['GOID'])\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'])\n",
    "combined_df = combined_df[combined_df['Date'].dt.year < 2024]\n",
    "combined_df[\"text_hash\"] = combined_df[\"Texts\"].apply(md5_hash_text)\n",
    "combined_df.drop_duplicates(subset=[\"text_hash\"], inplace=True)\n",
    "#combined_df.to_csv(\"ChicagoTribuneWithText.csv\")\n",
    "#combined_df.shape\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(help(Path()))\n",
    "path = Path.cwd()\n",
    "combined_df = pd.read_csv(path / f'{corpus_name}WithText.csv')\n",
    "combined_df['Texts'] = combined_df['Texts'].apply(ast.literal_eval)\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'])\n",
    "combined_df = combined_df[combined_df['Date'].dt.year < 2024]\n",
    "combined_df.head()\n",
    "#combined_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.copy()\n",
    "df['Texts'] = df['Texts'].apply(get_text_string)\n",
    "df['Year'] = df['Date'].dt.year\n",
    "publisher = df['Publisher'][0]\n",
    "\n",
    "dataframes = []\n",
    "threshold_list = [0, 300, 1000]\n",
    "for i in range(len(threshold_list)): \n",
    "    sub_df = df[df['WordCount'] > threshold_list[i]].reset_index()\n",
    "    sub_df = sub_df.groupby(['Publisher', 'Year']).size().reset_index(name='Count')\n",
    "    dataframes.append(sub_df)\n",
    "    print(f'sub_df_{i} shape is: {sub_df.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f953e1f4",
   "metadata": {},
   "source": [
    "### plot number of articles per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4d07d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df0, df1, df2 = dataframes[0], dataframes[1], dataframes[2], \n",
    "years = df0['Year']\n",
    "values1 = df0['Count']\n",
    "values2 = df1['Count']\n",
    "values3 = df2['Count']\n",
    "\n",
    "# Create a figure with 1 row and 3 columns of subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "# Plot the first bar chart\n",
    "axes[0].bar(years, values1)\n",
    "axes[0].set_title('all articles')\n",
    "axes[0].set_ylabel('count')\n",
    "axes[0].set_xlabel('year')\n",
    "\n",
    "# Plot the second bar chart\n",
    "axes[1].bar(years, values2)\n",
    "axes[1].set_title(f\"article's with more then {threshold_list[1] - 1} words\" )\n",
    "axes[1].set_xlabel('year')\n",
    "\n",
    "# Plot the third bar chart\n",
    "axes[2].bar(years, values3)\n",
    "axes[2].set_title(f\"article's with more then {threshold_list[2] - 1} words\")\n",
    "axes[2].set_xlabel('year')\n",
    "\n",
    "# Add a main title\n",
    "plt.suptitle(f\"Number of articles per Year in {publisher} for differnt word count thresholds\", fontsize=16)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Leave space for the main title\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
