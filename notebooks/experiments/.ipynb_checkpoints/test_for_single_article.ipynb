{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries and helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# set environment\n",
    "from pathlib import Path\n",
    "SRC_PATH = Path('/home/ec2-user/SageMaker/david/tdm-sentiment/src/')\n",
    "import sys\n",
    "sys.path.append(str(SRC_PATH))\n",
    "from config import *\n",
    "\n",
    "\n",
    "parser = tdm_parser.TdmXmlParser()\n",
    "\n",
    "def get_file_path():\n",
    "    \"\"\"\n",
    "    get file path from user given the corpus name and GOID number\n",
    "    \"\"\"\n",
    "    corpus_path = CORPUSES_PATH\n",
    "    corpus_name_mapping = {\n",
    "        'new york times': 'Newyork20240203',\n",
    "        'los angeles times': 'LosAngelesTimesDavid',\n",
    "        'washington post': 'TheWashingtonPostDavid',\n",
    "        'chicago tribune': 'ChicagoTribune',\n",
    "        'usa today': 'USATodayDavid'\n",
    "    }\n",
    "\n",
    "    # Get user input corpus name and normalize to lowercase\n",
    "    corpus_name_input = input('Please enter Newspaper Name: ').strip().lower()\n",
    "\n",
    "    # Check if the input is valid\n",
    "    while corpus_name_input not in corpus_name_mapping:\n",
    "        corpus_name_input = input('Please enter a Valid Newspaper Name: ').strip().lower()\n",
    "\n",
    "    # Construct the file path\n",
    "    corpus_name = corpus_name_mapping[corpus_name_input]\n",
    "    # Get user input GOID number and convert to int\n",
    "    goid_input = input('Please enter GOID number: ')\n",
    "    while not goid_input.isdigit():\n",
    "        goid_input = input('Please enter a Valid GOID number: ')\n",
    "\n",
    "    full_path = corpus_path / corpus_name / f'{goid_input}.xml'\n",
    "    return full_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get file path and get attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file_path = get_file_path()\n",
    "\n",
    "# examples\n",
    "# Newspaper: USA Today, GOID: 1027415041\n",
    "# Newspaper: usa today, GOID: 40900705\n",
    "# Newspaper: Chicago Tribune, GOID: 420425293\n",
    "# Newspaper: chicago tribune, GOID: 1552402040\n",
    "# Newspaper: los angeles times , GOID: 421073540\n",
    "# Newspaper: Los Angeles times, GOID: 421073540\n",
    "# Newspaper: new york times, GOID: 432877202\n",
    "# Newspaper: new york times, GOID: 759991258\n",
    "# Newspaper: washington post, GOID: 156229992\n",
    "# Newspaper: washington post, GOID: 1672802972\n",
    "\n",
    "#get attributes\n",
    "soup = parser.get_xml_soup(xml_file_path)  # get soup\n",
    "title = soup.find('Title').text.strip()    # extract title\n",
    "texts = parser.get_art_text(soup)          # extract text\n",
    "\n",
    "# print article attributes\n",
    "print(f'Title: {title} \\n')\n",
    "\n",
    "print('Text: \\n')\n",
    "for text in texts:  # print text\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model loaded successfully from 'C:\\Users\\pc\\Documents\\work\\bank of israel\\financial division\\yossi\\tdm-sentiment\\src\\sentiment\\sentiment_model\\distilbert-base-uncased-finetuned-sst-2-english' on device -1.\n",
      "[[{'label': 'NEGATIVE', 'score': 0.00012689229333773255}, {'label': 'POSITIVE', 'score': 0.9998730421066284}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sentiment.sentiment_model.sentiment_score_old as sentiment_score_old\n",
    "\n",
    "# Example usage:\n",
    "sentiment_analyzer = sentiment_score_old.TextAnalysis(SENTIMENT_MODEL_PATH_CLASSIC)\n",
    "pipeline_instance = sentiment_analyzer.get_pipeline()  # Retrieve the pipeline directly if needed\n",
    "\n",
    "text = \"I love using this model because it's really effective!\"\n",
    "def get_sentiment(text: str):\n",
    "    \"\"\"\n",
    "    Get all sentiment labels and their natural probabilities for the provided text\n",
    "    using the sentiment pipeline.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to analyze.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing each label's natural probability.\n",
    "              Each dictionary typically contains keys like 'label' and 'score'.\n",
    "    \"\"\"\n",
    "    return pipeline_instance(text, return_all_scores=True)\n",
    "\n",
    "\n",
    "result = get_sentiment(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Raw old probabilities:\n",
      "BERT model loaded successfully from 'C:\\Users\\pc\\Documents\\work\\bank of israel\\financial division\\yossi\\tdm-sentiment\\src\\sentiment\\sentiment_model\\distilbert-base-uncased-finetuned-sst-2-english' on device -1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: I love using this model because it's really effective!\n",
      "Sentiment distribution: {'negative': 0.00012689229333773255, 'positive': 0.9998730421066284}\n",
      "Overall sentiment score: 0.9997462153966763\n",
      "--------------------\n",
      "Raw finbert probabilities:\n",
      "BERT model loaded successfully from 'C:\\Users\\pc\\Documents\\work\\bank of israel\\financial division\\yossi\\tdm-sentiment\\src\\sentiment\\sentiment_model\\finbert_local' on device -1.\n",
      "text: I love using this model because it's really effective!\n",
      "Sentiment distribution: {'neutral': 0.00645602447912097, 'positive': 0.9934628009796143, 'negative': 8.122631697915494e-05}\n",
      "Overall sentiment score: 0.999836491761316\n"
     ]
    }
   ],
   "source": [
    "# set environment\n",
    "from pathlib import Path\n",
    "SRC_PATH = Path('/home/ec2-user/SageMaker/david/tdm-sentiment/src/')\n",
    "import sys\n",
    "sys.path.append(str(SRC_PATH))\n",
    "from config import *\n",
    "\n",
    "text = \"I love using this model because it's really effective!\"\n",
    "text = \"In recent years, the global economy has faced huge changes and unexpected challenges that are changing the way countries and industries operate. After the pandemic, it’s clear that flexible government spending, creative money management, and strong supply chains are essential. These shifts have exposed weak points in our system but also opened up new chances for growth and improvement.\"\n",
    "\n",
    "# Example usage classic model:\n",
    "sentiment_analyzer = sentiment_score.TextAnalysis(SENTIMENT_MODEL_PATH_CLASSIC)\n",
    "sentiment_dict = sentiment_analyzer.get_sentiment_dict(text)\n",
    "\n",
    "print('\\n', '-'*20)\n",
    "print(f'text: {text}\\n')\n",
    "print(\"Raw old probabilities:\")\n",
    "print(f'Sentiment distribution: {sentiment_dict}')\n",
    "\n",
    "# Get the computed overall sentiment score.\n",
    "score = sentiment_analyzer.txt_score(text)\n",
    "print(f\"Overall sentiment score: {score}\")\n",
    "print('-'*20, '\\n')\n",
    "\n",
    "\n",
    "# Example usage finbert model:\n",
    "sentiment_analyzer = sentiment_score.TextAnalysis(SENTIMENT_MODEL_PATH)\n",
    "sentiment_dict = sentiment_analyzer.get_sentiment_dict(text)\n",
    "\n",
    "print('\\n', '-'*20)\n",
    "print(f'text: {text}\\n')\n",
    "print(\"Raw finbert probabilities:\")\n",
    "print(f'Sentiment distribution: {sentiment_dict}')\n",
    "\n",
    "# Get the computed overall sentiment score.\n",
    "score = sentiment_analyzer.txt_score(text)\n",
    "print(f\"Overall sentiment score: {score}\")\n",
    "print('-'*20, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Replace with the model ID you want to download (e.g., FinBERT’s ID)\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "\n",
    "# This automatically downloads and caches the model, including 'pytorch_model.bin'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(\"PyTorch model and tokenizer downloaded successfully.\")\n",
    "\n",
    "# Define a local directory where you want to store the downloaded model files\n",
    "local_dir = \"./finbert_local\"\n",
    "\n",
    "# Save the model and tokenizer locally\n",
    "model.save_pretrained(local_dir)\n",
    "tokenizer.save_pretrained(local_dir)\n",
    "\n",
    "print(f\"Model and tokenizer have been saved to {local_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
