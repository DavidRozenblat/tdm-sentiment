{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e437ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidrozenblat/tdm-sentiment/.venv/lib/python3.12/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.5.2 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer model loaded from '/home/ec2-user/SageMaker/david/tdm-sentiment/src/topic_modeling/tf_idf_model/tfidf_vectorizer.pkl'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidrozenblat/tdm-sentiment/.venv/lib/python3.12/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.5.2 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# set environment\n",
    "from pathlib import Path\n",
    "SRC_PATH = Path('/home/ec2-user/SageMaker/david/tdm-sentiment/src/')\n",
    "import sys\n",
    "sys.path.append(str(SRC_PATH))\n",
    "from config import *\n",
    "tf_idf_extractor = tf_idf_extractor.TfidfKeywordExtractor(model_path=TF_IDF_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5780f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_corpus_tf_idf_tags(corpus_name):\n",
    "    result_folder_path = PROJECT_DATA_PATH / 'processed/results/' / corpus_name\n",
    "    properties_modifier.modify_csv_tf_idf(result_folder_path, corpus_name, tf_idf_extractor, top_n = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9acc7f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 0: chunk_0_data.csv Newyork20042023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk 0:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk 0: 100%|██████████| 20/20 [00:25<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files processed successfully!\n",
      "Processing chunk 0: chunk_0_data.csv LosAngelesTimesDavid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk 0: 100%|██████████| 20/20 [00:23<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files processed successfully!\n",
      "Processing chunk 0: chunk_0_data.csv TheWashingtonPostDavid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk 0: 100%|██████████| 25/25 [00:26<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files processed successfully!\n",
      "Processing chunk 0: chunk_0_data.csv ChicagoTribune\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk 0: 100%|██████████| 21/21 [00:22<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files processed successfully!\n",
      "Processing chunk 0: chunk_0_data.csv USATodayDavid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk 0: 100%|██████████| 20/20 [00:20<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files processed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Loop over each corpus in CORPUSES_LIST\n",
    "    for corpus_name in CORPUSES_LIST:\n",
    "        modify_corpus_tf_idf_tags(corpus_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
